# CodeRM-8B å®Œæ•´å®éªŒæµç¨‹ï¼ˆè¯¦ç»†ç‰ˆï¼‰

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—è¯¦ç»†è¯´æ˜å¦‚ä½•ä½¿ç”¨ **CodeRM-8B** ä½œä¸º Reward Model å¤ç° Table 2 çš„å®éªŒã€‚

### å®éªŒé…ç½®
- **Policy Model**: Llama3.1-8B-Instructï¼ˆç”Ÿæˆä»£ç è§£å†³æ–¹æ¡ˆï¼‰
- **Reward Model**: CodeRM-8Bï¼ˆç”Ÿæˆå•å…ƒæµ‹è¯•ï¼‰
- **Benchmark**: HumanEval+ï¼ˆ164 ä¸ªé—®é¢˜ï¼‰
- **æ¯ä¸ªé—®é¢˜ç”Ÿæˆ**: 100 ä¸ª solutions + 100 ä¸ª unit tests

### ä¸ Llama3.1-8B çš„åŒºåˆ«
- âœ… **Policy Model ç›¸åŒ**ï¼šä»ç„¶ä½¿ç”¨ Llama3.1-8B ç”Ÿæˆ solutions
- âœ… **Reward Model ä¸åŒ**ï¼šä½¿ç”¨ CodeRM-8B ç”Ÿæˆ unit tests
- âœ… **GPU éœ€æ±‚ç›¸åŒ**ï¼š1 å¼  GPUï¼ˆ~16GB æ˜¾å­˜ï¼‰
- âœ… **æµç¨‹åŸºæœ¬ç›¸åŒ**ï¼šåªéœ€ä¿®æ”¹é…ç½®æ–‡ä»¶

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

å¦‚æœä½ å·²ç»å®Œæˆäº† Llama3.1-8B çš„å®éªŒï¼Œ**åªéœ€è¦ä¿®æ”¹æ­¥éª¤ 2**ï¼ˆç”Ÿæˆ Unit Testsï¼‰ï¼š

```bash
# åœ¨æœåŠ¡å™¨ä¸Š
cd inference
python inference_mp.py --config config_ut_coderm-8b.json  # åªæ”¹è¿™ä¸€è¡Œï¼
```

ç„¶åç»§ç»­åç»­æ­¥éª¤ï¼Œå°† `llama3-8b` æ›¿æ¢ä¸º `coderm-8b`ã€‚

---

## ğŸ“ å®Œæ•´æµç¨‹

### é˜¶æ®µ 1: æœåŠ¡å™¨ - ç”Ÿæˆ Solutionsï¼ˆä¸ Llama3.1-8B ç›¸åŒï¼‰

**æ³¨æ„**ï¼šå¦‚æœä½ å·²ç»å®Œæˆäº† Llama3.1-8B çš„å®éªŒï¼Œå¯ä»¥**è·³è¿‡è¿™ä¸€æ­¥**ï¼Œç›´æ¥ä½¿ç”¨å·²æœ‰çš„ solutionsã€‚

```bash
# åœ¨æœåŠ¡å™¨ä¸Š
cd /path/to/CodeRM
conda activate coderm

# 1. ç”Ÿæˆ solutions
cd inference
python inference_mp.py --config config_sol_llama3-8b.json

# 2. åˆå¹¶è¾“å‡º
cd ../preprocess
python merge_output.py --mp_num 1 --input_dir ../output/inference/llama3-8b_solutions

# 3. æå– solutions
python extract_solution.py \
  --data_path ../output/inference/llama3-8b_solutions/merge_result.jsonl \
  --id_path ../data/benchmark/input_humaneval+_sol.jsonl \
  --output_path ../data/result/humaneval+/sol_llama3-8b_200.jsonl
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
- `data/result/humaneval+/sol_llama3-8b_200_anno.jsonl`ï¼ˆæ ‡æ³¨æ–‡ä»¶ï¼Œéœ€è¦è¿™ä¸ªï¼‰

---

### é˜¶æ®µ 2: æœåŠ¡å™¨ - ç”Ÿæˆ Unit Testsï¼ˆCodeRM-8Bï¼‰

#### æ­¥éª¤ 2.1: æ£€æŸ¥é…ç½®æ–‡ä»¶

```bash
# åœ¨æœåŠ¡å™¨ä¸Š
cd /path/to/CodeRM/inference
cat config_ut_coderm-8b.json
```

**é…ç½®æ–‡ä»¶å†…å®¹**ï¼š
```json
{
    "model_path": "KAKA22/CodeRM-8B",
    "dtype": "auto",
    "max_model_len": 4096,
    "gpu_memory_utilization": 0.8,
    "max_num_seqs": 512,
    "tensor_parallel_size": 1,
    "sampling_params": {
        "n": 100,
        "max_tokens": 2048,
        "top_p": 0.95,
        "temperature": 0.8,
        "stop": null
    },
    "num_gpus": 1,
    "output_dir": "../output/inference/coderm-8b_unit_tests",
    "messages_file": "../data/benchmark/input_humaneval+_ut.jsonl"
}
```

**å…³é”®å‚æ•°**ï¼š
- `model_path`: `KAKA22/CodeRM-8B`ï¼ˆCodeRM-8B æ¨¡å‹ï¼‰
- `num_gpus`: 1ï¼ˆéœ€è¦ 1 å¼  GPUï¼‰
- `n: 100`: æ¯ä¸ªé—®é¢˜ç”Ÿæˆ 100 ä¸ª unit tests

#### æ­¥éª¤ 2.2: è¿è¡Œæ¨ç†

```bash
# åœ¨æœåŠ¡å™¨ä¸Š
cd /path/to/CodeRM/inference

# è¿è¡Œæ¨ç†ï¼ˆä½¿ç”¨ CodeRM-8Bï¼‰
python inference_mp.py --config config_ut_coderm-8b.json
```

**æ‰§è¡Œè¿‡ç¨‹**ï¼š
1. è‡ªåŠ¨æ£€æµ‹ GPU
2. ä¸‹è½½ CodeRM-8B æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œï¼Œçº¦ 16GBï¼‰
3. åŠ è½½æ¨¡å‹åˆ° GPU
4. ç”Ÿæˆ unit testsï¼ˆ164 ä¸ªé—®é¢˜ Ã— 100 ä¸ª = 16,400 ä¸ªç”Ÿæˆä»»åŠ¡ï¼‰

**é¢„è®¡æ—¶é—´**ï¼š
- æ¨¡å‹ä¸‹è½½ï¼š10-30 åˆ†é’Ÿï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
- æ¨¡å‹åŠ è½½ï¼š1-2 åˆ†é’Ÿ
- ç”Ÿæˆ unit testsï¼š2-4 å°æ—¶

**ç›‘æ§ GPU**ï¼ˆåœ¨å¦ä¸€ä¸ªç»ˆç«¯ï¼‰ï¼š
```bash
watch -n 1 nvidia-smi
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
output/inference/coderm-8b_unit_tests/output_gpu_0.jsonl
```

#### æ­¥éª¤ 2.3: åˆå¹¶è¾“å‡º

```bash
# åœ¨æœåŠ¡å™¨ä¸Š
cd /path/to/CodeRM/preprocess

python merge_output.py --mp_num 1 --input_dir ../output/inference/coderm-8b_unit_tests
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
output/inference/coderm-8b_unit_tests/merge_result.jsonl
```

**éªŒè¯**ï¼š
```bash
ls -lh output/inference/coderm-8b_unit_tests/merge_result.jsonl
wc -l output/inference/coderm-8b_unit_tests/merge_result.jsonl  # åº”è¯¥æ˜¯ 164 è¡Œ
```

#### æ­¥éª¤ 2.4: æå– Unit Tests

```bash
# åœ¨æœåŠ¡å™¨ä¸Š
cd /path/to/CodeRM/preprocess

python extract_unit_test.py \
  --input_path ../output/inference/coderm-8b_unit_tests/merge_result.jsonl \
  --id_path ../data/benchmark/input_humaneval+_ut.jsonl \
  --output_path ../data/result/humaneval+/ut_coderm-8b_100.jsonl
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
data/result/humaneval+/ut_coderm-8b_100.jsonl
```

**éªŒè¯**ï¼š
```bash
# æ£€æŸ¥æ–‡ä»¶
head -n 1 data/result/humaneval+/ut_coderm-8b_100.jsonl | python3 -m json.tool
```

---

### é˜¶æ®µ 3: æ•°æ®ä¼ è¾“

ä»æœåŠ¡å™¨ä¸‹è½½ CodeRM-8B çš„ unit tests æ–‡ä»¶ï¼š

```bash
# åœ¨æœ¬åœ° Mac ä¸Šæ‰§è¡Œ
cd /Users/fyc/Desktop/CodeRM

# ä¸‹è½½ CodeRM-8B çš„ unit testsï¼ˆå…³é”®ï¼ï¼‰
scp user@server:/path/to/CodeRM/data/result/humaneval+/ut_coderm-8b_100.jsonl \
   ./data/result/humaneval+/

# å¦‚æœè¿˜æ²¡æœ‰ solutions æ–‡ä»¶ï¼Œä¹Ÿä¸‹è½½
scp user@server:/path/to/CodeRM/data/result/humaneval+/sol_llama3-8b_200_anno.jsonl \
   ./data/result/humaneval+/

# ç¡®ä¿ benchmark æ•°æ®å­˜åœ¨
scp user@server:/path/to/CodeRM/data/benchmark/input_humaneval+_sol.jsonl \
   ./data/benchmark/
scp user@server:/path/to/CodeRM/data/benchmark/input_humaneval+_ut.jsonl \
   ./data/benchmark/
```

**éªŒè¯**ï¼š
```bash
ls -lh data/result/humaneval+/ut_coderm-8b_100.jsonl
ls -lh data/result/humaneval+/sol_llama3-8b_200_anno.jsonl
```

---

### é˜¶æ®µ 4: æœ¬åœ° - Docker æ‰§è¡Œ

#### æ–¹æ³• A: ä¿®æ”¹è‡ªåŠ¨åŒ–è„šæœ¬

ç¼–è¾‘ `run_docker_local.sh`ï¼Œä¿®æ”¹ä»¥ä¸‹å˜é‡ï¼š

```bash
UT_MODEL="coderm-8b"  # æ”¹ä¸º coderm-8b
```

ç„¶åè¿è¡Œï¼š
```bash
bash run_docker_local.sh
```

#### æ–¹æ³• B: æ‰‹åŠ¨æ‰§è¡Œ

```bash
# åœ¨æœ¬åœ° Mac ä¸Š
cd /Users/fyc/Desktop/CodeRM

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p output/humaneval+/llama3-8b_sol_coderm-8b_ut/details

# ç”Ÿæˆ sol_ut.jsonlï¼ˆæ³¨æ„ï¼šsol_model æ˜¯ llama3-8bï¼Œut_model æ˜¯ coderm-8bï¼‰
python3 << 'PYTHON_SCRIPT'
import sys
sys.path.insert(0, '.')
from evaluation.evaluate import save_sol_and_ut_comb

save_sol_and_ut_comb('humaneval+', 'llama3-8b', 'coderm-8b', 100, 100)
print("å®Œæˆï¼")
PYTHON_SCRIPT

# æ‰§è¡Œ Docker
TEMP_DIR=$(mktemp -d -t docker_write_XXXXXX)
chmod 777 "$TEMP_DIR"

docker run -v "$(pwd):/data" kaka0605/exec_unit_test:24.12.30 \
    --input_path /data/output/humaneval+/llama3-8b_sol_coderm-8b_ut/details/sol_ut.jsonl \
    --output_path /data/$TEMP_DIR/100_sol_100_ut_result.jsonl \
    --mp_num 8 \
    --chunk_size 1000 \
    --recover 0

# ä¿å­˜ç»“æœ
mv $TEMP_DIR/100_sol_100_ut_result.jsonl \
   output/humaneval+/llama3-8b_sol_coderm-8b_ut/details/

# æ¸…ç†
rm output/humaneval+/llama3-8b_sol_coderm-8b_ut/details/sol_ut.jsonl
rmdir $TEMP_DIR
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
output/humaneval+/llama3-8b_sol_coderm-8b_ut/details/100_sol_100_ut_result.jsonl
```

**æ³¨æ„ç›®å½•ç»“æ„**ï¼š
- `llama3-8b_sol_coderm-8b_ut`ï¼šè¡¨ç¤º solutions æ¥è‡ª llama3-8bï¼Œunit tests æ¥è‡ª coderm-8b

---

### é˜¶æ®µ 5: è®¡ç®— Table 2 æŒ‡æ ‡

```bash
# åœ¨æœ¬åœ°ï¼ˆæˆ–æœåŠ¡å™¨ï¼‰
cd /Users/fyc/Desktop/CodeRM

# è®¡ç®—æŒ‡æ ‡ï¼ˆæ³¨æ„ ut_model æ˜¯ coderm-8bï¼‰
python evaluation/calculate_table2_metrics.py \
  --benchmark humaneval+ \
  --sol_model llama3-8b \
  --ut_model coderm-8b \
  --sol_num 100 \
  --ut_num 100 \
  --mode both \
  --output_dir output/table2_results
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
output/table2_results/humaneval+_llama3-8b_coderm-8b.json
```

**ç”Ÿæˆæ±‡æ€»**ï¼š
```bash
python evaluation/generate_table2_summary.py \
  --results_dir output/table2_results \
  --benchmark humaneval+ \
  --sol_model llama3-8b
```

---

## ğŸ“Š é¢„æœŸç»“æœ

æ ¹æ®è®ºæ–‡ Table 2ï¼ŒCodeRM-8B çš„é¢„æœŸç»“æœï¼š

### Individual Unit Tests
| æŒ‡æ ‡ | é¢„æœŸå€¼ |
|------|--------|
| Accuracy | 69.64 |
| F1 Score | 63.63 |
| FAR | 11.17 |
| FRR | 38.55 |

### Multiple Unit Tests
| æŒ‡æ ‡ | é¢„æœŸå€¼ |
|------|--------|
| Accuracy | 80.46 |
| F1 Score | 81.27 |
| FAR | 16.48 |
| FRR | 22.71 |

**æ³¨æ„**ï¼šCodeRM-8B åœ¨ Multiple Unit Tests æ¨¡å¼ä¸‹è¡¨ç°æœ€å¥½ï¼

---

## ğŸ”„ ä¸ Llama3.1-8B çš„å¯¹æ¯”

| é¡¹ç›® | Llama3.1-8B | CodeRM-8B |
|------|-------------|------------|
| é…ç½®æ–‡ä»¶ | `config_ut_llama3-8b.json` | `config_ut_coderm-8b.json` |
| æ¨¡å‹è·¯å¾„ | `meta-llama/Meta-Llama-3.1-8B-Instruct` | `KAKA22/CodeRM-8B` |
| GPU éœ€æ±‚ | 1 å¼  GPU | 1 å¼  GPU |
| è¾“å‡ºç›®å½• | `llama3-8b_unit_tests` | `coderm-8b_unit_tests` |
| Unit Test æ–‡ä»¶ | `ut_llama3-8b_100.jsonl` | `ut_coderm-8b_100.jsonl` |
| Docker è¾“å‡ºç›®å½• | `llama3-8b_sol_llama3-8b_ut` | `llama3-8b_sol_coderm-8b_ut` |
| æŒ‡æ ‡æ–‡ä»¶ | `humaneval+_llama3-8b_llama3-8b.json` | `humaneval+_llama3-8b_coderm-8b.json` |

---

## âœ… æ£€æŸ¥æ¸…å•

### é˜¶æ®µ 2 å®Œæˆ
- [ ] `output/inference/coderm-8b_unit_tests/output_gpu_0.jsonl` å­˜åœ¨
- [ ] `output/inference/coderm-8b_unit_tests/merge_result.jsonl` å­˜åœ¨
- [ ] `data/result/humaneval+/ut_coderm-8b_100.jsonl` å­˜åœ¨

### é˜¶æ®µ 3 å®Œæˆ
- [ ] æœ¬åœ°æœ‰ `data/result/humaneval+/ut_coderm-8b_100.jsonl`
- [ ] æœ¬åœ°æœ‰ `data/result/humaneval+/sol_llama3-8b_200_anno.jsonl`

### é˜¶æ®µ 4 å®Œæˆ
- [ ] `output/humaneval+/llama3-8b_sol_coderm-8b_ut/details/100_sol_100_ut_result.jsonl` å­˜åœ¨
- [ ] æ–‡ä»¶åŒ…å« 1,640,000 è¡Œç»“æœ

### é˜¶æ®µ 5 å®Œæˆ
- [ ] `output/table2_results/humaneval+_llama3-8b_coderm-8b.json` å­˜åœ¨
- [ ] æŒ‡æ ‡å€¼åœ¨åˆç†èŒƒå›´å†…

---

## ğŸ†˜ å¸¸è§é—®é¢˜

### é—®é¢˜ 1: CodeRM-8B æ¨¡å‹ä¸‹è½½å¤±è´¥

**é”™è¯¯**ï¼š
```
404 Client Error: Not Found
```

**è§£å†³**ï¼š
1. ç¡®è®¤æ¨¡å‹åç§°æ­£ç¡®ï¼š`KAKA22/CodeRM-8B`
2. æ£€æŸ¥ HuggingFace token æƒé™
3. è¿è¡Œï¼š`python test_token.py` éªŒè¯è®¿é—®æƒé™

### é—®é¢˜ 2: ç›®å½•åç§°ä¸åŒ¹é…

**é”™è¯¯**ï¼š
```
FileNotFoundError: .../llama3-8b_sol_coderm-8b_ut/...
```

**è§£å†³**ï¼š
- ç¡®ä¿ç›®å½•åç§°æ­£ç¡®ï¼š`llama3-8b_sol_coderm-8b_ut`
- æ³¨æ„ï¼šsolutions æ¥è‡ª `llama3-8b`ï¼Œunit tests æ¥è‡ª `coderm-8b`

### é—®é¢˜ 3: é…ç½®æ–‡ä»¶æ‰¾ä¸åˆ°

**é”™è¯¯**ï¼š
```
FileNotFoundError: config_ut_coderm-8b.json
```

**è§£å†³**ï¼š
- ç¡®è®¤æ–‡ä»¶å­˜åœ¨ï¼š`ls inference/config_ut_coderm-8b.json`
- å¦‚æœä¸å­˜åœ¨ï¼Œæ£€æŸ¥æ–‡ä»¶åæ˜¯å¦æ­£ç¡®

---

## ğŸš€ å¿«é€Ÿå‘½ä»¤å‚è€ƒ

### æœåŠ¡å™¨ç«¯

```bash
# ç”Ÿæˆ Unit Testsï¼ˆCodeRM-8Bï¼‰
cd inference
python inference_mp.py --config config_ut_coderm-8b.json

# åˆå¹¶å’Œæå–
cd ../preprocess
python merge_output.py --mp_num 1 --input_dir ../output/inference/coderm-8b_unit_tests
python extract_unit_test.py --input_path ../output/inference/coderm-8b_unit_tests/merge_result.jsonl --id_path ../data/benchmark/input_humaneval+_ut.jsonl --output_path ../data/result/humaneval+/ut_coderm-8b_100.jsonl
```

### æœ¬åœ°

```bash
# Docker æ‰§è¡Œï¼ˆæ‰‹åŠ¨ï¼‰
python3 -c "from evaluation.evaluate import save_sol_and_ut_comb; save_sol_and_ut_comb('humaneval+', 'llama3-8b', 'coderm-8b', 100, 100)"
TEMP_DIR=$(mktemp -d -t docker_write_XXXXXX)
chmod 777 "$TEMP_DIR"
docker run -v "$(pwd):/data" kaka0605/exec_unit_test:24.12.30 --input_path /data/output/humaneval+/llama3-8b_sol_coderm-8b_ut/details/sol_ut.jsonl --output_path /data/$TEMP_DIR/100_sol_100_ut_result.jsonl --mp_num 8 --chunk_size 1000 --recover 0
mv $TEMP_DIR/100_sol_100_ut_result.jsonl output/humaneval+/llama3-8b_sol_coderm-8b_ut/details/

# è®¡ç®—æŒ‡æ ‡
python evaluation/calculate_table2_metrics.py --benchmark humaneval+ --sol_model llama3-8b --ut_model coderm-8b --sol_num 100 --ut_num 100 --mode both
```

---

## ğŸ“ æ€»ç»“

ä½¿ç”¨ CodeRM-8B çš„æµç¨‹ä¸ Llama3.1-8B åŸºæœ¬ç›¸åŒï¼Œä¸»è¦åŒºåˆ«ï¼š

1. âœ… **é…ç½®æ–‡ä»¶**ï¼šä½¿ç”¨ `config_ut_coderm-8b.json`
2. âœ… **æ¨¡å‹è·¯å¾„**ï¼š`KAKA22/CodeRM-8B`
3. âœ… **è¾“å‡ºç›®å½•**ï¼š`coderm-8b_unit_tests` å’Œ `llama3-8b_sol_coderm-8b_ut`
4. âœ… **æŒ‡æ ‡è®¡ç®—**ï¼š`--ut_model coderm-8b`

**å¦‚æœä½ å·²ç»å®Œæˆäº† Llama3.1-8B çš„å®éªŒï¼Œåªéœ€è¦é‡æ–°è¿è¡Œé˜¶æ®µ 2-5 å³å¯ï¼**

ç¥å®éªŒé¡ºåˆ©ï¼ğŸš€
