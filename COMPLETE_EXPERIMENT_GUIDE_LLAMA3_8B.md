# Llama3.1-8B å®Œæ•´å®éªŒæµç¨‹ï¼ˆè¯¦ç»†ç‰ˆï¼‰

## ğŸ“‹ ç›®å½•

1. [å®éªŒæ¦‚è¿°](#å®éªŒæ¦‚è¿°)
2. [å‰ç½®æ¡ä»¶æ£€æŸ¥](#å‰ç½®æ¡ä»¶æ£€æŸ¥)
3. [é˜¶æ®µ 1: æœåŠ¡å™¨ - ç”Ÿæˆ Solutions](#é˜¶æ®µ-1-æœåŠ¡å™¨---ç”Ÿæˆ-solutions)
4. [é˜¶æ®µ 2: æœåŠ¡å™¨ - ç”Ÿæˆ Unit Tests](#é˜¶æ®µ-2-æœåŠ¡å™¨---ç”Ÿæˆ-unit-tests)
5. [é˜¶æ®µ 3: æ•°æ®ä¼ è¾“](#é˜¶æ®µ-3-æ•°æ®ä¼ è¾“)
6. [é˜¶æ®µ 4: æœ¬åœ° - Docker æ‰§è¡Œ](#é˜¶æ®µ-4-æœ¬åœ°---docker-æ‰§è¡Œ)
7. [é˜¶æ®µ 5: è®¡ç®— Table 2 æŒ‡æ ‡](#é˜¶æ®µ-5-è®¡ç®—-table-2-æŒ‡æ ‡)
8. [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)
9. [é¢„æœŸç»“æœ](#é¢„æœŸç»“æœ)

---

## å®éªŒæ¦‚è¿°

### å®éªŒç›®æ ‡
å¤ç° Table 2 ä¸­ **Llama3.1-8B** ä½œä¸º Reward Model çš„å®éªŒç»“æœã€‚

### å®éªŒé…ç½®
- **Policy Model**: Llama3.1-8B-Instructï¼ˆç”Ÿæˆä»£ç è§£å†³æ–¹æ¡ˆï¼‰
- **Reward Model**: Llama3.1-8B-Instructï¼ˆç”Ÿæˆå•å…ƒæµ‹è¯•ï¼‰
- **Benchmark**: HumanEval+ï¼ˆ164 ä¸ªé—®é¢˜ï¼‰
- **æ¯ä¸ªé—®é¢˜ç”Ÿæˆ**: 100 ä¸ª solutions + 100 ä¸ª unit tests
- **æ€»æ‰§è¡Œæ¬¡æ•°**: 164 Ã— 100 Ã— 100 = 1,640,000 æ¬¡å•å…ƒæµ‹è¯•æ‰§è¡Œ

### è®¡ç®—æŒ‡æ ‡
- Accuracy (Acc)
- F1 Score
- False Acceptance Rate (FAR)
- False Rejection Rate (FRR)
- Line Coverageï¼ˆè¡Œè¦†ç›–ç‡ï¼Œæ–°å¢ï¼‰

### å·¥ä½œæµåˆ†é…
- **æœåŠ¡å™¨ï¼ˆGPUï¼‰**: æ¨¡å‹æ¨ç†ï¼ˆç”Ÿæˆ solutions å’Œ unit testsï¼‰
- **æœ¬åœ°ï¼ˆMac + Dockerï¼‰**: æ‰§è¡Œå•å…ƒæµ‹è¯•ï¼ˆä¸éœ€è¦ GPUï¼‰

---

## å‰ç½®æ¡ä»¶æ£€æŸ¥

### æœåŠ¡å™¨ç«¯æ£€æŸ¥

#### 1.1 æ£€æŸ¥ GPU ç¯å¢ƒ

```bash
# åœ¨æœåŠ¡å™¨ä¸Š
cd /path/to/CodeRM
conda activate coderm

# è¿è¡Œ GPU æ£€æŸ¥è„šæœ¬
bash check_gpu.sh
```

**é¢„æœŸè¾“å‡º**ï¼š
```
âœ“ nvidia-smi å¯ç”¨
âœ“ PyTorch ç‰ˆæœ¬: 2.x.x
âœ“ CUDA å¯ç”¨
âœ“ GPU æ•°é‡: 1
âœ“ GPU 0: NVIDIA A100 (æˆ–ç±»ä¼¼)
âœ“ vLLM å·²å®‰è£…
```

**å¦‚æœæ£€æŸ¥å¤±è´¥**ï¼š
- æ£€æŸ¥ NVIDIA é©±åŠ¨ï¼š`nvidia-smi`
- æ£€æŸ¥ PyTorch CUDAï¼š`python -c "import torch; print(torch.cuda.is_available())"`
- å®‰è£… vLLMï¼š`pip install vllm==0.6.3.post1`

#### 1.2 æ£€æŸ¥ HuggingFace Token

```bash
# åœ¨æœåŠ¡å™¨ä¸Š
python test_token.py
```

**é¢„æœŸè¾“å‡º**ï¼š
```
âœ“ Token æœ‰æ•ˆ!
âœ“ ç”¨æˆ·: your_username
âœ“ å¯ä»¥è®¿é—® meta-llama/Meta-Llama-3.1-8B-Instruct
```

**å¦‚æœå¤±è´¥**ï¼š
- è¿è¡Œï¼š`huggingface-cli login` æˆ– `hf auth login`
- æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ï¼š`export HF_TOKEN="your_token"`

#### 1.3 æ£€æŸ¥æ•°æ®æ–‡ä»¶

```bash
# æ£€æŸ¥ benchmark æ•°æ®
ls -lh data/benchmark/input_humaneval+_sol.jsonl
ls -lh data/benchmark/input_humaneval+_ut.jsonl

# åº”è¯¥çœ‹åˆ°ä¸¤ä¸ªæ–‡ä»¶ï¼Œæ¯ä¸ªçº¦ 164 è¡Œ
```

**å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨**ï¼š
- ä»é¡¹ç›®ä»“åº“ä¸‹è½½
- æˆ–ä½¿ç”¨ `wget`/`curl` ä¸‹è½½

### æœ¬åœ°ï¼ˆMacï¼‰æ£€æŸ¥

#### 2.1 æ£€æŸ¥ Docker

```bash
# åœ¨æœ¬åœ° Mac ä¸Š
docker --version
docker ps
```

**é¢„æœŸè¾“å‡º**ï¼š
```
Docker version 24.x.x
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
```

**å¦‚æœå¤±è´¥**ï¼š
- å®‰è£… Docker Desktopï¼šhttps://www.docker.com/products/docker-desktop
- å¯åŠ¨ Docker Desktop åº”ç”¨

#### 2.2 æ‹‰å– Docker é•œåƒ

```bash
# åœ¨æœ¬åœ°
docker pull kaka0605/exec_unit_test:24.12.30

# éªŒè¯é•œåƒ
docker images | grep exec_unit_test
```

**é¢„æœŸè¾“å‡º**ï¼š
```
kaka0605/exec_unit_test   24.12.30    xxxxx    xxxxx    xxxx MB
```

#### 2.3 æ£€æŸ¥ Python ç¯å¢ƒ

```bash
# åœ¨æœ¬åœ°
cd /Users/fyc/Desktop/CodeRM
python3 --version

# æ£€æŸ¥å¿…è¦çš„ Python åŒ…
python3 -c "import json, tqdm; print('OK')"
```

---

## é˜¶æ®µ 1: æœåŠ¡å™¨ - ç”Ÿæˆ Solutions

### æ­¥éª¤ 1.1: å‡†å¤‡é…ç½®æ–‡ä»¶

ç¡®è®¤é…ç½®æ–‡ä»¶å­˜åœ¨ä¸”æ­£ç¡®ï¼š

```bash
# åœ¨æœåŠ¡å™¨ä¸Š
cd /path/to/CodeRM/inference
cat config_sol_llama3-8b.json
```

**é…ç½®æ–‡ä»¶å†…å®¹**ï¼š
```json
{
    "model_path": "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "dtype": "auto",
    "max_model_len": 4096,
    "gpu_memory_utilization": 0.8,
    "max_num_seqs": 512,
    "tensor_parallel_size": 1,
    "sampling_params": {
        "n": 100,
        "max_tokens": 2048,
        "top_p": 0.95,
        "temperature": 0.8,
        "stop": null
    },
    "num_gpus": 1,
    "output_dir": "../output/inference/llama3-8b_solutions",
    "messages_file": "../data/benchmark/input_humaneval+_sol.jsonl"
}
```

**å…³é”®å‚æ•°è¯´æ˜**ï¼š
- `n: 100`: æ¯ä¸ªé—®é¢˜ç”Ÿæˆ 100 ä¸ªè§£å†³æ–¹æ¡ˆ
- `num_gpus: 1`: ä½¿ç”¨ 1 ä¸ª GPU
- `gpu_memory_utilization: 0.8`: ä½¿ç”¨ 80% çš„ GPU æ˜¾å­˜

### æ­¥éª¤ 1.2: è¿è¡Œæ¨ç†

```bash
# åœ¨æœåŠ¡å™¨ä¸Š
cd /path/to/CodeRM/inference

# è¿è¡Œæ¨ç†ï¼ˆè¿™ä¼šè‡ªåŠ¨ä½¿ç”¨ GPUï¼‰
python inference_mp.py --config config_sol_llama3-8b.json
```

**æ‰§è¡Œè¿‡ç¨‹**ï¼š
1. ä»£ç ä¼šè‡ªåŠ¨è°ƒç”¨ `nvidia-smi` æ£€æµ‹å¯ç”¨ GPU
2. åˆ†é… GPUï¼ˆæ ¹æ® `num_gpus: 1`ï¼‰
3. ä¸‹è½½æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œï¼Œçº¦ 16GBï¼Œéœ€è¦æ—¶é—´ï¼‰
4. åŠ è½½æ¨¡å‹åˆ° GPU æ˜¾å­˜
5. å¼€å§‹ç”Ÿæˆ solutionsï¼ˆ164 ä¸ªé—®é¢˜ Ã— 100 ä¸ª = 16,400 ä¸ªç”Ÿæˆä»»åŠ¡ï¼‰

**é¢„è®¡æ—¶é—´**ï¼š
- æ¨¡å‹ä¸‹è½½ï¼š10-30 åˆ†é’Ÿï¼ˆé¦–æ¬¡è¿è¡Œï¼Œå–å†³äºç½‘ç»œï¼‰
- æ¨¡å‹åŠ è½½ï¼š1-2 åˆ†é’Ÿ
- ç”Ÿæˆ solutionsï¼š2-4 å°æ—¶ï¼ˆå–å†³äº GPU æ€§èƒ½ï¼‰

**ç›‘æ§ GPU**ï¼ˆåœ¨å¦ä¸€ä¸ªç»ˆç«¯ï¼‰ï¼š
```bash
watch -n 1 nvidia-smi
```

**é¢„æœŸçœ‹åˆ°**ï¼š
- GPU æ˜¾å­˜ä½¿ç”¨ï¼šçº¦ 12-16GB
- GPU åˆ©ç”¨ç‡ï¼šæ¥è¿‘ 100%
- æ¸©åº¦ï¼šå¯èƒ½ä¸Šå‡ï¼ˆæ­£å¸¸ï¼‰

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
output/inference/llama3-8b_solutions/output_gpu_0.jsonl
```

### æ­¥éª¤ 1.3: åˆå¹¶è¾“å‡ºæ–‡ä»¶

```bash
# åœ¨æœåŠ¡å™¨ä¸Š
cd /path/to/CodeRM/preprocess

# åˆå¹¶è¾“å‡ºï¼ˆmp_num = ä½¿ç”¨çš„ GPU æ•°é‡ï¼Œè¿™é‡Œæ˜¯ 1ï¼‰
python merge_output.py --mp_num 1 --input_dir ../output/inference/llama3-8b_solutions
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
output/inference/llama3-8b_solutions/merge_result.jsonl
```

**éªŒè¯**ï¼š
```bash
# æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆåº”è¯¥æœ‰å‡  GBï¼‰
ls -lh output/inference/llama3-8b_solutions/merge_result.jsonl

# æ£€æŸ¥è¡Œæ•°ï¼ˆåº”è¯¥æ˜¯ 164 è¡Œï¼Œæ¯è¡Œä¸€ä¸ªé—®é¢˜çš„ 100 ä¸ª responsesï¼‰
wc -l output/inference/llama3-8b_solutions/merge_result.jsonl
```

### æ­¥éª¤ 1.4: æå– Solutions

```bash
# åœ¨æœåŠ¡å™¨ä¸Š
cd /path/to/CodeRM/preprocess

python extract_solution.py \
  --data_path ../output/inference/llama3-8b_solutions/merge_result.jsonl \
  --id_path ../data/benchmark/input_humaneval+_sol.jsonl \
  --output_path ../data/result/humaneval+/sol_llama3-8b_200.jsonl
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
data/result/humaneval+/sol_llama3-8b_200.jsonl
```

**éªŒè¯**ï¼š
```bash
# æ£€æŸ¥æ–‡ä»¶
head -n 1 data/result/humaneval+/sol_llama3-8b_200.jsonl | python3 -m json.tool

# åº”è¯¥çœ‹åˆ°ç±»ä¼¼ï¼š
# {
#   "task_id": "HumanEval/0",
#   "solutions": [
#     "def has_close_elements(...)",
#     ...
#   ]
# }
```

**æ³¨æ„**ï¼šå¦‚æœä½ å·²ç»æœ‰ `sol_llama3-8b_200_anno.jsonl`ï¼ˆæ ‡æ³¨æ–‡ä»¶ï¼‰ï¼Œå¯ä»¥è·³è¿‡ç”Ÿæˆæ­¥éª¤ï¼Œç›´æ¥ä½¿ç”¨ç°æœ‰æ–‡ä»¶ã€‚ä½†ä¸ºäº†å®Œæ•´å¤ç°ï¼Œå»ºè®®é‡æ–°ç”Ÿæˆã€‚

---

## é˜¶æ®µ 2: æœåŠ¡å™¨ - ç”Ÿæˆ Unit Tests

### æ­¥éª¤ 2.1: å‡†å¤‡é…ç½®æ–‡ä»¶

```bash
# åœ¨æœåŠ¡å™¨ä¸Š
cd /path/to/CodeRM/inference
cat config_ut_llama3-8b.json
```

**é…ç½®æ–‡ä»¶å†…å®¹**ï¼š
```json
{
    "model_path": "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "dtype": "auto",
    "max_model_len": 4096,
    "gpu_memory_utilization": 0.8,
    "max_num_seqs": 512,
    "tensor_parallel_size": 1,
    "sampling_params": {
        "n": 100,
        "max_tokens": 2048,
        "top_p": 0.95,
        "temperature": 0.8,
        "stop": null
    },
    "num_gpus": 1,
    "output_dir": "../output/inference/llama3-8b_unit_tests",
    "messages_file": "../data/benchmark/input_humaneval+_ut.jsonl"
}
```

### æ­¥éª¤ 2.2: è¿è¡Œæ¨ç†

```bash
# åœ¨æœåŠ¡å™¨ä¸Š
cd /path/to/CodeRM/inference

# è¿è¡Œæ¨ç†
python inference_mp.py --config config_ut_llama3-8b.json
```

**æ‰§è¡Œè¿‡ç¨‹**ï¼š
- ä¸ç”Ÿæˆ solutions ç±»ä¼¼
- 164 ä¸ªé—®é¢˜ Ã— 100 ä¸ª = 16,400 ä¸ªç”Ÿæˆä»»åŠ¡
- é¢„è®¡æ—¶é—´ï¼š2-4 å°æ—¶

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
output/inference/llama3-8b_unit_tests/output_gpu_0.jsonl
```

### æ­¥éª¤ 2.3: åˆå¹¶è¾“å‡º

```bash
# åœ¨æœåŠ¡å™¨ä¸Š
cd /path/to/CodeRM/preprocess

python merge_output.py --mp_num 1 --input_dir ../output/inference/llama3-8b_unit_tests
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
output/inference/llama3-8b_unit_tests/merge_result.jsonl
```

### æ­¥éª¤ 2.4: æå– Unit Tests

```bash
# åœ¨æœåŠ¡å™¨ä¸Š
cd /path/to/CodeRM/preprocess

python extract_unit_test.py \
  --input_path ../output/inference/llama3-8b_unit_tests/merge_result.jsonl \
  --id_path ../data/benchmark/input_humaneval+_ut.jsonl \
  --output_path ../data/result/humaneval+/ut_llama3-8b_100.jsonl
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
data/result/humaneval+/ut_llama3-8b_100.jsonl
```

**éªŒè¯**ï¼š
```bash
# æ£€æŸ¥æ–‡ä»¶
head -n 1 data/result/humaneval+/ut_llama3-8b_100.jsonl | python3 -m json.tool

# åº”è¯¥çœ‹åˆ°ç±»ä¼¼ï¼š
# {
#   "task_id": "HumanEval/0",
#   "unit_tests": [
#     "import unittest\nclass Test...",
#     ...
#   ]
# }
```

---

## é˜¶æ®µ 3: æ•°æ®ä¼ è¾“

### æ­¥éª¤ 3.1: ä»æœåŠ¡å™¨ä¸‹è½½å¿…è¦æ–‡ä»¶

**åœ¨æœ¬åœ° Mac ä¸Šæ‰§è¡Œ**ï¼ˆæ›¿æ¢ `user@server:/path/to/CodeRM` ä¸ºä½ çš„å®é™…æœåŠ¡å™¨åœ°å€ï¼‰ï¼š

```bash
# åœ¨æœ¬åœ°
cd /Users/fyc/Desktop/CodeRM

# åˆ›å»ºå¿…è¦çš„ç›®å½•
mkdir -p data/result/humaneval+
mkdir -p data/benchmark
mkdir -p output/humaneval+/llama3-8b_sol_llama3-8b_ut/details

# 1. ä¸‹è½½ solutionsï¼ˆæ ‡æ³¨æ–‡ä»¶ï¼ŒåŒ…å«æ­£ç¡®/é”™è¯¯æ ‡ç­¾ï¼‰
scp user@server:/path/to/CodeRM/data/result/humaneval+/sol_llama3-8b_200_anno.jsonl \
   ./data/result/humaneval+/

# 2. ä¸‹è½½ unit tests
scp user@server:/path/to/CodeRM/data/result/humaneval+/ut_llama3-8b_100.jsonl \
   ./data/result/humaneval+/

# 3. ä¸‹è½½ benchmark æ•°æ®ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
scp user@server:/path/to/CodeRM/data/benchmark/input_humaneval+_sol.jsonl \
   ./data/benchmark/
scp user@server:/path/to/CodeRM/data/benchmark/input_humaneval+_ut.jsonl \
   ./data/benchmark/
```

**éªŒè¯ä¸‹è½½**ï¼š
```bash
# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls -lh data/result/humaneval+/sol_llama3-8b_200_anno.jsonl
ls -lh data/result/humaneval+/ut_llama3-8b_100.jsonl
ls -lh data/benchmark/input_humaneval+_sol.jsonl
ls -lh data/benchmark/input_humaneval+_ut.jsonl

# æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆåº”è¯¥éƒ½æ˜¯å‡  MB åˆ°å‡ å MBï¼‰
```

**å¦‚æœ scp å¾ˆæ…¢**ï¼š
- å¯ä»¥ä½¿ç”¨ `rsync`ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰ï¼š
```bash
rsync -avz --progress user@server:/path/to/CodeRM/data/result/humaneval+/sol_llama3-8b_200_anno.jsonl \
   ./data/result/humaneval+/
```

---

## é˜¶æ®µ 4: æœ¬åœ° - Docker æ‰§è¡Œ

### æ­¥éª¤ 4.1: ä½¿ç”¨è‡ªåŠ¨åŒ–è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# åœ¨æœ¬åœ° Mac ä¸Š
cd /Users/fyc/Desktop/CodeRM

# è¿è¡Œè‡ªåŠ¨åŒ–è„šæœ¬
bash run_docker_local.sh
```

**è„šæœ¬ä¼šè‡ªåŠ¨**ï¼š
1. æ£€æŸ¥ Docker å’Œé•œåƒ
2. æ£€æŸ¥æ•°æ®æ–‡ä»¶
3. ç”Ÿæˆ `sol_ut.jsonl`ï¼ˆè§£å†³æ–¹æ¡ˆ-å•å…ƒæµ‹è¯•ç»„åˆæ–‡ä»¶ï¼‰
4. æ‰§è¡Œ Docker å®¹å™¨
5. ä¿å­˜ç»“æœæ–‡ä»¶
6. æ¸…ç†ä¸´æ—¶æ–‡ä»¶

**é¢„è®¡æ—¶é—´**ï¼š2-6 å°æ—¶ï¼ˆå–å†³äº Mac æ€§èƒ½ï¼‰

### æ­¥éª¤ 4.2: æ‰‹åŠ¨æ‰§è¡Œï¼ˆå¦‚æœéœ€è¦ï¼‰

å¦‚æœè„šæœ¬æœ‰é—®é¢˜ï¼Œå¯ä»¥æ‰‹åŠ¨æ‰§è¡Œï¼š

#### 4.2.1 ç”Ÿæˆ sol_ut.jsonl

```bash
# åœ¨æœ¬åœ°
cd /Users/fyc/Desktop/CodeRM

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p output/humaneval+/llama3-8b_sol_llama3-8b_ut/details

# ç”Ÿæˆç»„åˆæ–‡ä»¶
python3 << 'PYTHON_SCRIPT'
import sys
sys.path.insert(0, '.')
from evaluation.evaluate import save_sol_and_ut_comb

print("ç”Ÿæˆ sol_ut.jsonl...")
save_sol_and_ut_comb('humaneval+', 'llama3-8b', 'llama3-8b', 100, 100)
print("å®Œæˆï¼")
PYTHON_SCRIPT
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
output/humaneval+/llama3-8b_sol_llama3-8b_ut/details/sol_ut.jsonl
```

**éªŒè¯**ï¼š
```bash
# æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆåº”è¯¥å¾ˆå¤§ï¼Œå‡  GBï¼‰
ls -lh output/humaneval+/llama3-8b_sol_llama3-8b_ut/details/sol_ut.jsonl

# æ£€æŸ¥è¡Œæ•°ï¼ˆåº”è¯¥æ˜¯ 1,640,000 è¡Œï¼‰
wc -l output/humaneval+/llama3-8b_sol_llama3-8b_ut/details/sol_ut.jsonl
```

#### 4.2.2 æ‰§è¡Œ Docker

```bash
# åœ¨æœ¬åœ°
cd /Users/fyc/Desktop/CodeRM

# åˆ›å»ºä¸´æ—¶ç›®å½•
TEMP_DIR=$(mktemp -d -t docker_write_XXXXXX)
chmod 777 "$TEMP_DIR"
echo "ä¸´æ—¶ç›®å½•: $TEMP_DIR"

# æ‰§è¡Œ Docker å®¹å™¨
docker run -v "$(pwd):/data" kaka0605/exec_unit_test:24.12.30 \
    --input_path /data/output/humaneval+/llama3-8b_sol_llama3-8b_ut/details/sol_ut.jsonl \
    --output_path /data/$TEMP_DIR/100_sol_100_ut_result.jsonl \
    --mp_num 8 \
    --chunk_size 1000 \
    --recover 0
```

**å‚æ•°è¯´æ˜**ï¼š
- `--mp_num 8`: ä½¿ç”¨ 8 ä¸ªè¿›ç¨‹å¹¶è¡Œæ‰§è¡Œ
- `--chunk_size 1000`: æ¯æ¬¡å¤„ç† 1000 æ¡
- `--recover 0`: ä¸æ¢å¤ï¼ˆä»å¤´å¼€å§‹ï¼‰

**ç›‘æ§è¿›åº¦**ï¼š
Docker ä¼šè¾“å‡ºè¿›åº¦ä¿¡æ¯ï¼Œæ˜¾ç¤ºå·²å¤„ç†çš„æ•°é‡ã€‚

**é¢„è®¡æ—¶é—´**ï¼š2-6 å°æ—¶

#### 4.2.3 ä¿å­˜ç»“æœ

```bash
# ç§»åŠ¨ç»“æœæ–‡ä»¶
mv $TEMP_DIR/100_sol_100_ut_result.jsonl \
   output/humaneval+/llama3-8b_sol_llama3-8b_ut/details/

# æ¸…ç†
rm output/humaneval+/llama3-8b_sol_llama3-8b_ut/details/sol_ut.jsonl
rmdir $TEMP_DIR
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
output/humaneval+/llama3-8b_sol_llama3-8b_ut/details/100_sol_100_ut_result.jsonl
```

**éªŒè¯**ï¼š
```bash
# æ£€æŸ¥æ–‡ä»¶
head -n 1 output/humaneval+/llama3-8b_sol_llama3-8b_ut/details/100_sol_100_ut_result.jsonl | python3 -m json.tool

# åº”è¯¥çœ‹åˆ°ç±»ä¼¼ï¼š
# {
#   "task_id": "HumanEval/0",
#   "sol_id": 0,
#   "ut_id": 0,
#   "result": "pass"  // æˆ– "fail" æˆ– "error"
# }
```

---

## é˜¶æ®µ 5: è®¡ç®— Table 2 æŒ‡æ ‡

### æ­¥éª¤ 5.1: è®¡ç®—æŒ‡æ ‡ï¼ˆä¸è®¡ç®—è¦†ç›–ç‡ï¼Œå¿«é€Ÿï¼‰

```bash
# åœ¨æœ¬åœ°ï¼ˆæˆ–æœåŠ¡å™¨ï¼Œå¦‚æœç»“æœæ–‡ä»¶åœ¨æœåŠ¡å™¨ä¸Šï¼‰
cd /Users/fyc/Desktop/CodeRM

python evaluation/calculate_table2_metrics.py \
  --benchmark humaneval+ \
  --sol_model llama3-8b \
  --ut_model llama3-8b \
  --sol_num 100 \
  --ut_num 100 \
  --mode both \
  --output_dir output/table2_results
```

**å‚æ•°è¯´æ˜**ï¼š
- `--mode both`: è®¡ç®— Individual å’Œ Multiple ä¸¤ç§æ¨¡å¼çš„æŒ‡æ ‡
- `--output_dir`: ç»“æœä¿å­˜ç›®å½•

**é¢„è®¡æ—¶é—´**ï¼š10-30 åˆ†é’Ÿ

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
output/table2_results/humaneval+_llama3-8b_llama3-8b.json
```

**è¾“å‡ºå†…å®¹**ï¼š
```json
{
  "individual": {
    "accuracy": 60.02,
    "f1": 44.97,
    "far": 13.66,
    "frr": 46.13,
    "line_coverage": 0.0
  },
  "multiple": {
    "accuracy": 74.21,
    "f1": 74.35,
    "far": 20.44,
    "frr": 30.55,
    "line_coverage": 0.0
  }
}
```

### æ­¥éª¤ 5.2: è®¡ç®—æŒ‡æ ‡ï¼ˆåŒ…å«è¡Œè¦†ç›–ç‡ï¼Œæ…¢ï¼‰

å¦‚æœéœ€è¦è®¡ç®—è¡Œè¦†ç›–ç‡ï¼š

```bash
python evaluation/calculate_table2_metrics.py \
  --benchmark humaneval+ \
  --sol_model llama3-8b \
  --ut_model llama3-8b \
  --sol_num 100 \
  --ut_num 100 \
  --mode both \
  --output_dir output/table2_results \
  --calculate_coverage
```

**æ³¨æ„**ï¼šè¡Œè¦†ç›–ç‡è®¡ç®—å¾ˆæ…¢ï¼Œä¼šå¯¹æ¯ä¸ª solution çš„å‰å‡ ä¸ª unit test é‡‡æ ·è®¡ç®—ã€‚

### æ­¥éª¤ 5.3: ç”Ÿæˆæ±‡æ€»è¡¨æ ¼

```bash
# åœ¨æœ¬åœ°
python evaluation/generate_table2_summary.py \
  --results_dir output/table2_results \
  --benchmark humaneval+ \
  --sol_model llama3-8b
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
```
output/table2_results/table2_summary_humaneval+.md
```

**è¾“å‡ºå†…å®¹**ï¼ˆMarkdown è¡¨æ ¼ï¼‰ï¼š
```markdown
# Table 2: Quality of Unit Tests

## Quality of Individual Unit Tests

| Model | Acc (â†‘) | F1 (â†‘) | FAR (â†“) | FRR (â†“) | Line Coverage (â†‘) |
|-------|---------|--------|---------|---------|-------------------|
| Llama3.1-8B | 60.02 | 44.97 | 13.66 | 46.13 | 0.00 |

## Quality of Multiple Unit Tests

| Model | Acc (â†‘) | F1 (â†‘) | FAR (â†“) | FRR (â†“) | Line Coverage (â†‘) |
|-------|---------|--------|---------|---------|-------------------|
| Llama3.1-8B | 74.21 | 74.35 | 20.44 | 30.55 | 0.00 |
```

---

## æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: GPU æ£€æµ‹å¤±è´¥

**é”™è¯¯**ï¼š
```
AssertionError: len(free_gpus) >= config['num_gpus']
```

**è§£å†³**ï¼š
1. æ£€æŸ¥ GPUï¼š`nvidia-smi`
2. é™ä½é˜ˆå€¼ï¼ˆä¿®æ”¹ `inference_mp.py` ç¬¬ 158 è¡Œï¼‰ï¼š
   ```python
   free_gpus = get_free_gpus(threshold=10000)  # æ”¹ä¸º 10GB
   ```
3. æ‰‹åŠ¨æŒ‡å®š GPUï¼š
   ```python
   free_gpus = [0]  # ä½¿ç”¨ GPU 0
   ```

### é—®é¢˜ 2: æ˜¾å­˜ä¸è¶³ï¼ˆOOMï¼‰

**é”™è¯¯**ï¼š
```
CUDA out of memory
```

**è§£å†³**ï¼š
1. é™ä½ `gpu_memory_utilization`ï¼ˆé…ç½®æ–‡ä»¶ï¼‰ï¼š
   ```json
   "gpu_memory_utilization": 0.7
   ```
2. å‡å°‘ `max_num_seqs`ï¼š
   ```json
   "max_num_seqs": 256
   ```
3. å‡å°‘ `max_model_len`ï¼š
   ```json
   "max_model_len": 2048
   ```

### é—®é¢˜ 3: Docker æ‰§è¡Œå¤±è´¥

**é”™è¯¯**ï¼š
```
permission denied
```

**è§£å†³**ï¼š
1. æ£€æŸ¥ Docker æ˜¯å¦è¿è¡Œï¼š`docker ps`
2. æ£€æŸ¥é•œåƒï¼š`docker images | grep exec_unit_test`
3. é‡æ–°æ‹‰å–é•œåƒï¼š`docker pull kaka0605/exec_unit_test:24.12.30`

### é—®é¢˜ 4: æ•°æ®æ–‡ä»¶ç¼ºå¤±

**é”™è¯¯**ï¼š
```
FileNotFoundError: ...
```

**è§£å†³**ï¼š
1. æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
2. ç¡®è®¤æ–‡ä»¶å·²ä»æœåŠ¡å™¨ä¸‹è½½
3. æ£€æŸ¥æ–‡ä»¶æƒé™ï¼š`ls -lh data/result/humaneval+/`

### é—®é¢˜ 5: æŒ‡æ ‡è®¡ç®—é”™è¯¯

**é”™è¯¯**ï¼š
```
KeyError: 'plus_status'
```

**è§£å†³**ï¼š
1. ç¡®è®¤ä½¿ç”¨ `sol_llama3-8b_200_anno.jsonl`ï¼ˆæ ‡æ³¨æ–‡ä»¶ï¼‰
2. æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®
3. ç¡®è®¤ benchmark åç§°æ˜¯ `humaneval+`ï¼ˆä¸æ˜¯ `humaneval`ï¼‰

---

## é¢„æœŸç»“æœ

æ ¹æ®è®ºæ–‡ Table 2ï¼ŒLlama3.1-8B çš„é¢„æœŸç»“æœï¼š

### Individual Unit Tests
| æŒ‡æ ‡ | é¢„æœŸå€¼ |
|------|--------|
| Accuracy | 60.02 |
| F1 Score | 44.97 |
| FAR | 13.66 |
| FRR | 46.13 |

### Multiple Unit Tests
| æŒ‡æ ‡ | é¢„æœŸå€¼ |
|------|--------|
| Accuracy | 74.21 |
| F1 Score | 74.35 |
| FAR | 20.44 |
| FRR | 30.55 |

**æ³¨æ„**ï¼šå®é™…ç»“æœå¯èƒ½ç•¥æœ‰å·®å¼‚ï¼Œå› ä¸ºï¼š
- éšæœºæ€§ï¼ˆtemperature, seedï¼‰
- æ¨¡å‹ç‰ˆæœ¬å·®å¼‚
- ç¡¬ä»¶å·®å¼‚

---

## æ—¶é—´ä¼°ç®—

| é˜¶æ®µ | é¢„è®¡æ—¶é—´ |
|------|----------|
| æœåŠ¡å™¨ GPU æ¨ç†ï¼ˆSolutionsï¼‰ | 2-4 å°æ—¶ |
| æœåŠ¡å™¨ GPU æ¨ç†ï¼ˆUnit Testsï¼‰ | 2-4 å°æ—¶ |
| æ•°æ®ä¼ è¾“ | 5-30 åˆ†é’Ÿ |
| æœ¬åœ° Docker æ‰§è¡Œ | 2-6 å°æ—¶ |
| æŒ‡æ ‡è®¡ç®— | 10-30 åˆ†é’Ÿ |
| **æ€»è®¡** | **6-15 å°æ—¶** |

---

## æ£€æŸ¥æ¸…å•

å®Œæˆæ¯ä¸ªé˜¶æ®µåï¼Œæ£€æŸ¥ä»¥ä¸‹é¡¹ç›®ï¼š

### é˜¶æ®µ 1 å®Œæˆ
- [ ] `output/inference/llama3-8b_solutions/output_gpu_0.jsonl` å­˜åœ¨
- [ ] `output/inference/llama3-8b_solutions/merge_result.jsonl` å­˜åœ¨
- [ ] `data/result/humaneval+/sol_llama3-8b_200.jsonl` å­˜åœ¨

### é˜¶æ®µ 2 å®Œæˆ
- [ ] `output/inference/llama3-8b_unit_tests/output_gpu_0.jsonl` å­˜åœ¨
- [ ] `output/inference/llama3-8b_unit_tests/merge_result.jsonl` å­˜åœ¨
- [ ] `data/result/humaneval+/ut_llama3-8b_100.jsonl` å­˜åœ¨

### é˜¶æ®µ 3 å®Œæˆ
- [ ] æœ¬åœ°æœ‰ `data/result/humaneval+/sol_llama3-8b_200_anno.jsonl`
- [ ] æœ¬åœ°æœ‰ `data/result/humaneval+/ut_llama3-8b_100.jsonl`
- [ ] æœ¬åœ°æœ‰ `data/benchmark/input_humaneval+_sol.jsonl`
- [ ] æœ¬åœ°æœ‰ `data/benchmark/input_humaneval+_ut.jsonl`

### é˜¶æ®µ 4 å®Œæˆ
- [ ] `output/humaneval+/llama3-8b_sol_llama3-8b_ut/details/100_sol_100_ut_result.jsonl` å­˜åœ¨
- [ ] æ–‡ä»¶å¤§å°åˆç†ï¼ˆå‡  GBï¼‰
- [ ] æ–‡ä»¶åŒ…å« 1,640,000 è¡Œç»“æœ

### é˜¶æ®µ 5 å®Œæˆ
- [ ] `output/table2_results/humaneval+_llama3-8b_llama3-8b.json` å­˜åœ¨
- [ ] `output/table2_results/table2_summary_humaneval+.md` å­˜åœ¨
- [ ] æŒ‡æ ‡å€¼åœ¨åˆç†èŒƒå›´å†…

---

## ä¸‹ä¸€æ­¥

å®Œæˆ Llama3.1-8B åï¼Œå¯ä»¥ç»§ç»­ï¼š

1. **Llama3.1-70B**ï¼š
   - éœ€è¦ 4 å¼  GPU
   - ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼š`config_ut_llama3-70b.json`
   - é‡å¤ç›¸åŒæµç¨‹

2. **CodeRM-8B**ï¼š
   - éœ€è¦ 1 å¼  GPU
   - ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼š`config_ut_coderm-8b.json`
   - é‡å¤ç›¸åŒæµç¨‹

3. **ç”Ÿæˆå®Œæ•´ Table 2**ï¼š
   ```bash
   python evaluation/generate_table2_summary.py \
     --results_dir output/table2_results \
     --benchmark humaneval+ \
     --sol_model llama3-8b
   ```

---

## æ€»ç»“

è¿™ä¸ªæµç¨‹æ¶µç›–äº†ä» GPU æ¨ç†åˆ°æŒ‡æ ‡è®¡ç®—çš„å®Œæ•´è¿‡ç¨‹ã€‚å…³é”®ç‚¹ï¼š

1. âœ… **æœåŠ¡å™¨è‡ªåŠ¨ä½¿ç”¨ GPU**ï¼šä»£ç ä¼šè‡ªåŠ¨æ£€æµ‹å’Œåˆ†é… GPU
2. âœ… **æœ¬åœ°æ‰§è¡Œ Docker**ï¼šä¸éœ€è¦ GPUï¼Œå¯ä»¥åœ¨ Mac ä¸Šè¿è¡Œ
3. âœ… **æ•°æ®é€šè¿‡ scp ä¼ è¾“**ï¼šç®€å•å¯é 
4. âœ… **è‡ªåŠ¨åŒ–è„šæœ¬**ï¼šç®€åŒ– Docker æ‰§è¡Œæµç¨‹

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œå‚è€ƒæ•…éšœæ’æŸ¥éƒ¨åˆ†ï¼Œæˆ–è¿è¡Œæ£€æŸ¥è„šæœ¬è¯Šæ–­é—®é¢˜ã€‚

**ç¥å®éªŒé¡ºåˆ©ï¼** ğŸš€
