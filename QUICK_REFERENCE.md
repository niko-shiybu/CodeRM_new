# Llama3.1-8B å®éªŒå¿«é€Ÿå‚è€ƒ

## ğŸš€ å¿«é€Ÿå‘½ä»¤æ¸…å•

### æœåŠ¡å™¨ç«¯ï¼ˆGPU æ¨ç†ï¼‰

```bash
# 1. æ£€æŸ¥ç¯å¢ƒ
bash check_gpu.sh
python test_token.py

# 2. ç”Ÿæˆ Solutions
cd inference
python inference_mp.py --config config_sol_llama3-8b.json
cd ../preprocess
python merge_output.py --mp_num 1 --input_dir ../output/inference/llama3-8b_solutions
python extract_solution.py --data_path ../output/inference/llama3-8b_solutions/merge_result.jsonl --id_path ../data/benchmark/input_humaneval+_sol.jsonl --output_path ../data/result/humaneval+/sol_llama3-8b_200.jsonl

# 3. ç”Ÿæˆ Unit Tests
cd ../inference
python inference_mp.py --config config_ut_llama3-8b.json
cd ../preprocess
python merge_output.py --mp_num 1 --input_dir ../output/inference/llama3-8b_unit_tests
python extract_unit_test.py --input_path ../output/inference/llama3-8b_unit_tests/merge_result.jsonl --id_path ../data/benchmark/input_humaneval+_ut.jsonl --output_path ../data/result/humaneval+/ut_llama3-8b_100.jsonl
```

### æ•°æ®ä¼ è¾“ï¼ˆæœåŠ¡å™¨ â†’ æœ¬åœ°ï¼‰

```bash
# åœ¨æœ¬åœ° Mac æ‰§è¡Œ
scp user@server:/path/to/CodeRM/data/result/humaneval+/sol_llama3-8b_200_anno.jsonl ./data/result/humaneval+/
scp user@server:/path/to/CodeRM/data/result/humaneval+/ut_llama3-8b_100.jsonl ./data/result/humaneval+/
scp user@server:/path/to/CodeRM/data/benchmark/input_humaneval+_sol.jsonl ./data/benchmark/
scp user@server:/path/to/CodeRM/data/benchmark/input_humaneval+_ut.jsonl ./data/benchmark/
```

### æœ¬åœ°ï¼ˆDocker æ‰§è¡Œï¼‰

```bash
# ä¸€é”®è¿è¡Œ
bash run_docker_local.sh

# æˆ–æ‰‹åŠ¨æ‰§è¡Œ
python3 -c "from evaluation.evaluate import save_sol_and_ut_comb; save_sol_and_ut_comb('humaneval+', 'llama3-8b', 'llama3-8b', 100, 100)"
TEMP_DIR=$(mktemp -d -t docker_write_XXXXXX)
chmod 777 "$TEMP_DIR"
docker run -v "$(pwd):/data" kaka0605/exec_unit_test:24.12.30 --input_path /data/output/humaneval+/llama3-8b_sol_llama3-8b_ut/details/sol_ut.jsonl --output_path /data/$TEMP_DIR/100_sol_100_ut_result.jsonl --mp_num 8 --chunk_size 1000 --recover 0
mv $TEMP_DIR/100_sol_100_ut_result.jsonl output/humaneval+/llama3-8b_sol_llama3-8b_ut/details/
```

### è®¡ç®—æŒ‡æ ‡

```bash
# è®¡ç®—æŒ‡æ ‡ï¼ˆå¿«é€Ÿï¼‰
python evaluation/calculate_table2_metrics.py --benchmark humaneval+ --sol_model llama3-8b --ut_model llama3-8b --sol_num 100 --ut_num 100 --mode both

# ç”Ÿæˆæ±‡æ€»
python evaluation/generate_table2_summary.py --results_dir output/table2_results --benchmark humaneval+ --sol_model llama3-8b
```

## ğŸ“Š é¢„æœŸç»“æœ

| æ¨¡å¼ | Acc | F1 | FAR | FRR |
|------|-----|----|----|-----|
| Individual | 60.02 | 44.97 | 13.66 | 46.13 |
| Multiple | 74.21 | 74.35 | 20.44 | 30.55 |

## â±ï¸ æ—¶é—´ä¼°ç®—

- GPU æ¨ç†ï¼š4-8 å°æ—¶
- Docker æ‰§è¡Œï¼š2-6 å°æ—¶
- æŒ‡æ ‡è®¡ç®—ï¼š10-30 åˆ†é’Ÿ
- **æ€»è®¡**ï¼š6-15 å°æ—¶

## ğŸ“ å…³é”®æ–‡ä»¶è·¯å¾„

### æœåŠ¡å™¨ç«¯
- Solutions: `data/result/humaneval+/sol_llama3-8b_200_anno.jsonl`
- Unit Tests: `data/result/humaneval+/ut_llama3-8b_100.jsonl`

### æœ¬åœ°
- Docker ç»“æœ: `output/humaneval+/llama3-8b_sol_llama3-8b_ut/details/100_sol_100_ut_result.jsonl`
- æŒ‡æ ‡ç»“æœ: `output/table2_results/humaneval+_llama3-8b_llama3-8b.json`

## ğŸ” æ£€æŸ¥ç‚¹

- [ ] GPU å¯ç”¨ï¼š`nvidia-smi`
- [ ] Token æœ‰æ•ˆï¼š`python test_token.py`
- [ ] Docker è¿è¡Œï¼š`docker ps`
- [ ] æ•°æ®æ–‡ä»¶å­˜åœ¨ï¼šæ£€æŸ¥ `data/result/humaneval+/`

## ğŸ†˜ å¸¸è§é—®é¢˜

- **GPU æ£€æµ‹å¤±è´¥**ï¼šé™ä½é˜ˆå€¼æˆ–æ‰‹åŠ¨æŒ‡å®š GPU
- **æ˜¾å­˜ä¸è¶³**ï¼šé™ä½ `gpu_memory_utilization`
- **Docker å¤±è´¥**ï¼šæ£€æŸ¥é•œåƒå’Œæƒé™
- **æ–‡ä»¶ç¼ºå¤±**ï¼šé‡æ–°ä¸‹è½½æˆ–ç”Ÿæˆ

è¯¦ç»†è¯´æ˜è¯·æŸ¥çœ‹ï¼š`COMPLETE_EXPERIMENT_GUIDE_LLAMA3_8B.md`
